{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###Translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "image = cv2.imread('images/input.jpg')\n",
    "\n",
    "height, width = image.shape[:2]\n",
    "\n",
    "quarter_height, quarter_width = height/4, width/4\n",
    "\n",
    "T = np.float32([[1, 0, quarter_width], [0, 1,quarter_height]])\n",
    "\n",
    "img_translation = cv2.warpAffine(image, T, (width, height))\n",
    "cv2.imshow('Translation', img_translation)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###Rotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "image = cv2.imread('images/input.jpg')\n",
    "height, width = image.shape[:2]\n",
    "\n",
    "\n",
    "rotation_matrix = cv2.getRotationMatrix2D((width/2, height/2), 90, .5)\n",
    "\n",
    "rotated_image = cv2.warpAffine(image, rotation_matrix, (width, height))\n",
    "\n",
    "cv2.imshow('Rotated Image', rotated_image)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Rotations-Transpose\n",
    "img = cv2.imread('images/input.jpg')\n",
    "\n",
    "rotated_image = cv2.transpose(img)\n",
    "\n",
    "cv2.imshow('Rotated Image - Method 2', rotated_image)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Horizontal Flip\n",
    "flipped = cv2.flip(image, 1)\n",
    "cv2.imshow('Horizontal Flip', flipped) \n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###Scaling, Resizing and Interpolations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "image = cv2.imread('images/input.jpg')\n",
    "\n",
    "\n",
    "image_scaled = cv2.resize(image, None, fx=0.75, fy=0.75)\n",
    "cv2.imshow('Scaling - Linear Interpolation', image_scaled) \n",
    "cv2.waitKey()\n",
    "\n",
    "\n",
    "img_scaled = cv2.resize(image, None, fx=2, fy=2, interpolation = cv2.INTER_CUBIC)\n",
    "cv2.imshow('Scaling - Cubic Interpolation', img_scaled)\n",
    "cv2.waitKey()\n",
    "\n",
    "\n",
    "img_scaled = cv2.resize(image, (900, 400), interpolation = cv2.INTER_AREA)\n",
    "cv2.imshow('Scaling - INTER_AREA', img_scaled) \n",
    "cv2.waitKey()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###Image Pyramids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "image = cv2.imread('images/input.jpg')\n",
    "\n",
    "smaller = cv2.pyrDown(image)\n",
    "larger = cv2.pyrUp(smaller)\n",
    "\n",
    "cv2.imshow('Original', image )\n",
    "cv2.imshow('Smaller ', smaller )\n",
    "cv2.imshow('Larger ', larger )\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###Cropping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "image = cv2.imread('images/input.jpg')\n",
    "height, width = image.shape[:2]\n",
    "\n",
    "\n",
    "start_row, start_col = int(height * .25), int(width * .25)\n",
    "\n",
    "\n",
    "end_row, end_col = int(height * .75), int(width * .75)\n",
    "\n",
    "\n",
    "cropped = image[start_row:end_row , start_col:end_col]\n",
    "\n",
    "cv2.imshow(\"Original Image\", image)\n",
    "cv2.waitKey(0) \n",
    "cv2.imshow(\"Cropped Image\", cropped) \n",
    "cv2.waitKey(0) \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###Arithmetic Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "image = cv2.imread('images/input.jpg')\n",
    "\n",
    "\n",
    "M = np.ones(image.shape, dtype = \"uint8\") * 175\n",
    "\n",
    "\n",
    "added = cv2.add(image, M)\n",
    "cv2.imshow(\"Added\", added)\n",
    "\n",
    "\n",
    "subtracted = cv2.subtract(image, M)\n",
    "cv2.imshow(\"Subtracted\", subtracted)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###Bitwise Operations and Masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "square = np.zeros((300, 300), np.uint8)\n",
    "cv2.rectangle(square, (50, 50), (250, 250), 255, -2)\n",
    "cv2.imshow(\"Square\", square)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "\n",
    "ellipse = np.zeros((300, 300), np.uint8)\n",
    "cv2.ellipse(ellipse, (150, 150), (150, 150), 30, 0, 180, 255, -1)\n",
    "cv2.imshow(\"Ellipse\", ellipse)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "And = cv2.bitwise_and(square, ellipse)\n",
    "cv2.imshow(\"AND\", And)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "\n",
    "bitwiseOr = cv2.bitwise_or(square, ellipse)\n",
    "cv2.imshow(\"OR\", bitwiseOr)\n",
    "cv2.waitKey(0) \n",
    "\n",
    "\n",
    "bitwiseXor = cv2.bitwise_xor(square, ellipse)\n",
    "cv2.imshow(\"XOR\", bitwiseXor)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "\n",
    "bitwiseNot_sq = cv2.bitwise_not(square)\n",
    "cv2.imshow(\"NOT - square\", bitwiseNot_sq)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###Convolutions and Blurring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "image = cv2.imread('images/input.jpg')\n",
    "cv2.imshow('Original Image', image)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "\n",
    "kernel_3x3 = np.ones((3, 3), np.float32) / 9\n",
    "\n",
    "\n",
    "blurred = cv2.filter2D(image, -1, kernel_3x3)\n",
    "cv2.imshow('3x3 Kernel Blurring', blurred)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "\n",
    "kernel_7x7 = np.ones((7, 7), np.float32) / 49\n",
    "\n",
    "blurred2 = cv2.filter2D(image, -1, kernel_7x7)\n",
    "cv2.imshow('7x7 Kernel Blurring', blurred2)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###Sharpening "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "image = cv2.imread('images/input.jpg')\n",
    "cv2.imshow('Original', image)\n",
    "\n",
    "\n",
    "kernel_sharpening = np.array([[-1,-1,-1], \n",
    "                              [-1,9,-1], \n",
    "                              [-1,-1,-1]])\n",
    "\n",
    "\n",
    "sharpened = cv2.filter2D(image, -1, kernel_sharpening)\n",
    "\n",
    "cv2.imshow('Image Sharpening', sharpened)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###Thresholding, Binarization & Adaptive Thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "image = cv2.imread('images/gradient.jpg',0)\n",
    "cv2.imshow('Original', image)\n",
    "\n",
    "\n",
    "ret,thresh1 = cv2.threshold(image, 127, 255, cv2.THRESH_BINARY)\n",
    "cv2.imshow('1 Threshold Binary', thresh1)\n",
    "\n",
    "\n",
    "ret,thresh2 = cv2.threshold(image, 127, 255, cv2.THRESH_BINARY_INV)\n",
    "cv2.imshow('2 Threshold Binary Inverse', thresh2)\n",
    "\n",
    "\n",
    "ret,thresh3 = cv2.threshold(image, 127, 255, cv2.THRESH_TRUNC)\n",
    "cv2.imshow('3 THRESH TRUNC', thresh3)\n",
    "\n",
    "\n",
    "ret,thresh4 = cv2.threshold(image, 127, 255, cv2.THRESH_TOZERO)\n",
    "cv2.imshow('4 THRESH TOZERO', thresh4)\n",
    "\n",
    "\n",
    "ret,thresh5 = cv2.threshold(image, 127, 255, cv2.THRESH_TOZERO_INV)\n",
    "cv2.imshow('5 THRESH TOZERO INV', thresh5)\n",
    "cv2.waitKey(0) \n",
    "    \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "image = cv2.imread('images/Origin_of_Species.jpg', 0)\n",
    "\n",
    "cv2.imshow('Original', image)\n",
    "cv2.waitKey(0) \n",
    "\n",
    "\n",
    "ret,thresh1 = cv2.threshold(image, 127, 255, cv2.THRESH_BINARY)\n",
    "cv2.imshow('Threshold Binary', thresh1)\n",
    "cv2.waitKey(0) \n",
    "\n",
    "image = cv2.GaussianBlur(image, (3, 3), 0)\n",
    "cv2.imshow('GaussianBlur', thresh1)\n",
    "cv2.waitKey(0) \n",
    "\n",
    "\n",
    "thresh = cv2.adaptiveThreshold(image, 255, cv2.ADAPTIVE_THRESH_MEAN_C, \n",
    "                               cv2.THRESH_BINARY, 3, 5) \n",
    "cv2.imshow(\"Adaptive Mean Thresholding\", thresh) \n",
    "cv2.waitKey(0) \n",
    "\n",
    "_, th2 = cv2.threshold(image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "cv2.imshow(\"Otsu's Thresholding\", thresh) \n",
    "cv2.waitKey(0) \n",
    "\n",
    "\n",
    "blur = cv2.GaussianBlur(image, (5,5), 0)\n",
    "_, th3 = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "cv2.imshow(\"Guassian Otsu's Thresholding\", thresh) \n",
    "cv2.waitKey(0) \n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Dilation, Erosion, Opening and Closing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "image = cv2.imread('images/opencv_inv.png', 0)\n",
    "\n",
    "cv2.imshow('Original', image)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "kernel = np.ones((5,5), np.uint8)\n",
    "\n",
    "erosion = cv2.erode(image, kernel, iterations = 1)\n",
    "cv2.imshow('Erosion', erosion)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "dilation = cv2.dilate(image, kernel, iterations = 1)\n",
    "cv2.imshow('Dilation', dilation)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "opening = cv2.morphologyEx(image, cv2.MORPH_OPEN, kernel)\n",
    "cv2.imshow('Opening', opening)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "closing = cv2.morphologyEx(image, cv2.MORPH_CLOSE, kernel)\n",
    "cv2.imshow('Closing', closing)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###Edge Detection & Image Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "image = cv2.imread('images/input.jpg',0)\n",
    "\n",
    "height, width = image.shape\n",
    "\n",
    "sobel_x = cv2.Sobel(image, cv2.CV_64F, 0, 1, ksize=5)\n",
    "sobel_y = cv2.Sobel(image, cv2.CV_64F, 1, 0, ksize=5)\n",
    "\n",
    "cv2.imshow('Original', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.imshow('Sobel X', sobel_x)\n",
    "cv2.waitKey(0)\n",
    "cv2.imshow('Sobel Y', sobel_y)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "sobel_OR = cv2.bitwise_or(sobel_x, sobel_y)\n",
    "cv2.imshow('sobel_OR', sobel_OR)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "laplacian = cv2.Laplacian(image, cv2.CV_64F)\n",
    "cv2.imshow('Laplacian', laplacian)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "\n",
    "canny = cv2.Canny(image, 50, 120)\n",
    "cv2.imshow('Canny', canny)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###Getting Perpsective Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "image = cv2.imread('images/scan.jpg')\n",
    "\n",
    "cv2.imshow('Original', image)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "points_A = np.float32([[320,15], [700,215], [85,610], [530,780]])\n",
    "\n",
    "points_B = np.float32([[0,0], [420,0], [0,594], [420,594]])\n",
    " \n",
    "M = cv2.getPerspectiveTransform(points_A, points_B)\n",
    " \n",
    "warped = cv2.warpPerspective(image, M, (420,594))\n",
    " \n",
    "cv2.imshow('warpPerspective', warped)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### In affine transforms you only need 3 coordiantes to obtain the correct transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "image = cv2.imread('images/ex2.jpg')\n",
    "rows,cols,ch = image.shape\n",
    "\n",
    "cv2.imshow('Original', image)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "points_A = np.float32([[320,15], [700,215], [85,610]])\n",
    "\n",
    "points_B = np.float32([[0,0], [420,0], [0,594]])\n",
    "\n",
    "M = cv2.getAffineTransform(points_A, points_B)\n",
    "\n",
    "warped = cv2.warpAffine(image, M, (cols, rows))\n",
    " \n",
    "cv2.imshow('warpPerspective', warped)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###Live Sketch Using Webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def sketch(image):\n",
    "    img_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    img_gray_blur = cv2.GaussianBlur(img_gray, (3, 3), 0)\n",
    "    \n",
    "    canny_edges = cv2.Canny(img_gray_blur, 10, 70)\n",
    "    \n",
    "    ret, mask = cv2.threshold(canny_edges, 70, 255, cv2.THRESH_BINARY_INV)\n",
    "    return mask\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    cv2.imshow('Project1', sketch(frame))\n",
    "    k = cv2.waitKey(1) & 0xFF\n",
    "    if  k == 27 : \n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    " \n",
    "def Change_threhole(x):\n",
    " \n",
    "  T1 = cv2.getTrackbarPos('T1','home_canny')\n",
    "  T2 = cv2.getTrackbarPos('T2','home_canny')\n",
    "  edges = cv2.Canny(img,T1,T2)\n",
    "  cv2.imshow('home_canny',edges)\n",
    "  cv2.imshow('home',img)\n",
    "   \n",
    "cv2.namedWindow('home_canny', cv2.WINDOW_NORMAL)  \n",
    "cv2.namedWindow('home', cv2.WINDOW_NORMAL) \n",
    "   \n",
    "cv2.createTrackbar('T1','home_canny',0,500,Change_threhole)\n",
    "cv2.createTrackbar('T2','home_canny',0,500,Change_threhole)\n",
    " \n",
    "img = cv2.imread('images/input.jpg',0)\n",
    "edges = cv2.Canny(img,150,300) \n",
    "cv2.imshow('home_canny',edges)\n",
    "cv2.imshow('home',img)\n",
    " \n",
    "k = cv2.waitKey(0) & 0xFF\n",
    "if k == 27:\n",
    " cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
